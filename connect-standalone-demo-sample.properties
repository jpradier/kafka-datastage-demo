bootstrap.servers=<YOUR BOOTSTRAP>
## Consumer specific properties
group.id=ibmeventstreams_starter_app_group
auto.offset.reset=earliest
enable.auto.commit=false
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
## Producer specific properties
acks=all
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer
## Optional security options
security.protocol=SASL_SSL
ssl.protocol=TLSv1.2
sasl.jaas.config=<YOUR JAAS CONFIG>
sasl.mechanism=PLAIN
ssl.enabled.protocols=TLSv1.2
ssl.endpoint.identification.algorithm=HTTPS
## Optional security options for producer
consumer.security.protocol=SASL_SSL
consumer.ssl.protocol=TLSv1.2
consumer.sasl.jaas.config=<YOUR JAAS CONFIG>
consumer.sasl.mechanism=PLAIN
consumer.ssl.enabled.protocols=TLSv1.2
consumer.ssl.endpoint.identification.algorithm=HTTPS
## Optional security options for consumer
producer.security.protocol=SASL_SSL
producer.ssl.protocol=TLSv1.2
producer.sasl.jaas.config=<YOUR JAAS CONFIG>
producer.sasl.mechanism=PLAIN
producer.ssl.enabled.protocols=TLSv1.2
producer.ssl.endpoint.identification.algorithm=HTTPS

# The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
# need to configure these based on the format they want their data in when loaded from or stored into Kafka
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter
# Converter-specific settings can be passed in by prefixing the Converter's setting with the converter we want to apply
# it to
key.converter.schemas.enable=true
value.converter.schemas.enable=true

offset.storage.file.filename=/tmp/connect.offsets
# Flush much faster than normal, which is useful for testing/debugging
offset.flush.interval.ms=10000
plugin.path=<YOUR PATH>/kafka-connect-stockprice-source-0.0.3-jar-with-dependencies.jar
# bin/connect-standalone.sh config/connect-standalone-demo.properties config/file-sink-standalone.properties
# bin/kafka-console-producer.sh -bootstrap-server localhost:9092 -topic file-sink-standalone-test
# bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic STOCK.IBM
# bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --partitions 1 --replication-factor 1 --topic STOCK.IBM
# bin/connect-standalone.sh config/connect-standalone-demo.properties config/file-sink-standalone.properties
# bin/connect-standalone.sh ../../kafka-connect-stockprice-source/connect-standalone-demo.properties ../../kafka-connect-stockprice-source/stock-aapl-connector.properties
# bin/connect-standalone.sh ../../kafka-connect-stockprice-source/connect-standalone-demo.properties ../../kafka-connect-stockprice-source/stock-msft-connector.properties
